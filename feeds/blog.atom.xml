<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Penguinsula - Blog</title><link href="https://jwarmenhoven.github.io/" rel="alternate"></link><link href="https://jwarmenhoven.github.io/feeds/blog.atom.xml" rel="self"></link><id>https://jwarmenhoven.github.io/</id><updated>2023-08-01T00:00:00+02:00</updated><subtitle>Python, Stats, Modelling &amp; Stuff</subtitle><entry><title>Synology NAS | NFSv4 | Kerberos | Linux Client</title><link href="https://jwarmenhoven.github.io/Setting-up-NFS4-Kerberos-Linux-Synology-NAS.html" rel="alternate"></link><published>2023-08-01T00:00:00+02:00</published><updated>2023-08-01T00:00:00+02:00</updated><author><name>Jordi Warmenhoven</name></author><id>tag:jwarmenhoven.github.io,2023-08-01:/Setting-up-NFS4-Kerberos-Linux-Synology-NAS.html</id><summary type="html">&lt;p&gt;Many people have a Network Attached Storage (NAS) server in their home networks to share files and perhaps function as a private cloud. These NAS servers usually offer different ways (protocols) to share files with devices on the network. Most common protocols are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block"&gt;Server Message Block (SMB)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Network_File_System"&gt;Network File System â€¦&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;Many people have a Network Attached Storage (NAS) server in their home networks to share files and perhaps function as a private cloud. These NAS servers usually offer different ways (protocols) to share files with devices on the network. Most common protocols are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block"&gt;Server Message Block (SMB)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Network_File_System"&gt;Network File System (NFS)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Apple_Filing_Protocol"&gt;Apple Filing Protocol (AFP)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The SMB protocol is the standard in Windows networks, whereas NFS is used more in Unix/Linux environments. I have a &lt;a href="https://www.synology.com/"&gt;Synology&lt;/a&gt; NAS and have both Linux and Microsoft Windows clients connecting to the fileserver. &lt;/p&gt;
&lt;p&gt;SMB works fine on Linux too, but there are a number of advantages in using NFS which I will not detail here. However, certain steps in NFS configuration are especially important to make file permissions work properly/securely with version 4 of the NFS protocol. This has to do with how user accounts on the NAS are mapped and authorized to the user accounts on the Linux client. A quick and dirty setup on the Synology NAS is possible: mapping all connecting NFS clients to a guest account on the NAS. As a consequence, owners of the files created on the NFS share are mapped to user &lt;code&gt;nobody&lt;/code&gt;. With this setup I ran into issues with using &lt;code&gt;git&lt;/code&gt; on the NFS fileshares since my Linux user was not the owner of the repository files.&lt;/p&gt;
&lt;p&gt;Below I describe how I configured NFSv4 + Kerberos on the Synology NAS and my Linux client in order to work properly with regards to file ownership and permissions. This is by no means an exhaustive description and assumes some prior knowledge on the subjects, but hopefully it gives some form of guidance.&lt;/p&gt;
&lt;blockquote&gt;
&lt;h4&gt;System environment:&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;NFS Server&lt;/strong&gt;: Synology DS216+ NAS running DSM 7.1.1-42962 Update 6&lt;ul&gt;
&lt;li&gt;NFSv4  &lt;/li&gt;
&lt;li&gt;Kerberos 5 v1.18.3  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;NFS Client&lt;/strong&gt;: Manjaro Linux running a 6.3 kernel&lt;ul&gt;
&lt;li&gt;Mounting NFSv4 share on NAS.&lt;/li&gt;
&lt;li&gt;Running Kerberos KDC (Kerberos Distribution Center). In larger networks the KDC would typically run on a separate server. &lt;/li&gt;
&lt;li&gt;Kerberos 5 v1.19.4   &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;No DNS on local network&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h4&gt;Kerberos&lt;/h4&gt;
&lt;p&gt;NSFv4 clients are authenticated on user level. This can be done using standard UNIX authentication (AUTH_SYS), but then user accounts on client and NAS need to match on UID/GID level as I understand it. The other authentication method uses &lt;a href="https://en.wikipedia.org/wiki/Kerberos_(protocol)"&gt;Kerberos&lt;/a&gt;. Understanding how Kerberos works (high level) takes some time. It is typically one of those things where you will need to read documentation, try things out, re-read documentation and try some more.&lt;/p&gt;
&lt;p&gt;Here are a number of resources which I found useful:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://kerberos.org/software/tutorial.html"&gt;Tutorial (kerberos.org)&lt;/a&gt; &lt;br&gt;
  I suggest to start here.  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://web.mit.edu/kerberos/krb5-latest/doc/"&gt;Official Documentation (web.mit.edu)&lt;/a&gt; &lt;br&gt;
  This is a collection of separate HTML pages. I found the single pdf file contained in the &lt;a href="http://web.mit.edu/kerberos/dist/"&gt;releases&lt;/a&gt; easier to navigate.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://wiki.archlinux.org/title/Kerberos"&gt;Kerberos on Arch Wiki&lt;/a&gt; &lt;br&gt;
  I run the Manjaro Distribution, which is based on Arch Linux.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://techpubs.spinlocksolutions.com/dklar/kerberos.html"&gt;Kerberos Tutorial Debian/Ubuntu&lt;/a&gt; &lt;br&gt;
  Not all parts are applicable to Manjaro (and perhaps not anymore to Debian either?), but still very informative.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://linuskarlsson.se/blog/acquiring-kerberos-ticket-upon-local-login/"&gt;Generate Kerberos tickets at login&lt;/a&gt; using PAM.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Linux man files on the various config files, programs and protocols.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h4&gt;NFS Client&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Enable NFS client services&lt;/strong&gt;: &lt;br&gt;
&lt;code&gt;sudo systemctl enable nfs-client.target&lt;/code&gt; &lt;br&gt;
  The &lt;a href="https://kb.synology.com/en-br/DSM/help/DSM/AdminCenter/file_winmacnfs_nfs?version=7"&gt;Synology documentation&lt;/a&gt; mentions that &lt;em&gt;idmapd&lt;/em&gt; needs to be enabled. However, I noticed that the Linux idmapd manual says that only NFSv4 &lt;em&gt;servers&lt;/em&gt; need to have that daemon running. The client on newer Linux kernels now uses the &lt;em&gt;nfsidmap&lt;/em&gt; program to do name mapping. No need to enable idmapd. However, you do need to set the NFSv4 domain identical to the Kerberos Realm in &lt;code&gt;/etc/idmapd.conf&lt;/code&gt;. This config file is used by other programs as well according to the manual page.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Configure&lt;code&gt;/etc/hosts&lt;/code&gt;&lt;/strong&gt; &lt;br&gt;
  The hostname of the client (and KDC) must be mapped to the LAN ip address, &lt;em&gt;not&lt;/em&gt; the 127.* address.&lt;br&gt;
  The hostname of the service/server (NAS) must be mapped to the LAN ip address (unless you have DNS running).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Maintain Kerberos configuration in &lt;code&gt;/etc/krb5.conf&lt;/code&gt;&lt;/strong&gt;  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Section &lt;code&gt;[libdefaults]&lt;/code&gt;: set your &lt;code&gt;default_realm&lt;/code&gt; to a name you want to use for your Kerberos realm. Convention is to use the DNS domain in capital letters, but if you do not use DNS in your local network you can of course pick something else.&lt;/li&gt;
&lt;li&gt;Section &lt;code&gt;[realms]&lt;/code&gt;: map the &lt;code&gt;admin_server&lt;/code&gt; and &lt;code&gt;kdc&lt;/code&gt;for your realm to the ip address/FQDN of your linux client.&lt;/li&gt;
&lt;li&gt;Section &lt;code&gt;[domain_realm]&lt;/code&gt;: map the domain to your realm.   &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Add an administrator user to the Kerberos Access Control List &lt;code&gt;/var/lib/krb5kdc/kadm5.acl&lt;/code&gt;&lt;/strong&gt;&lt;br&gt;
  See documentation/resources mentioned above regarding the format of this file.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Configure Kerberos database&lt;/strong&gt;  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;After initial creation of the database, use &lt;code&gt;$sudo kadmin_local&lt;/code&gt; to add the administrator principal to the database. After having added this principal, you can from now on use &lt;code&gt;$kadmin&lt;/code&gt; which interacts with the database &lt;em&gt;via the kadmind daemon&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Add a standard principal that is your user on the Linux client.&lt;/li&gt;
&lt;li&gt;Add a service principal for the NAS/NFSv4 server.   &lt;/li&gt;
&lt;li&gt;Add a service principal for the KDC (the Linux client).&lt;br&gt;
Restart krb5-kadmind and krb5-kdc services with command &lt;code&gt;sudo systemctl restart&lt;/code&gt;.  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Export the principal key for the server to the &lt;code&gt;/etc/krb5.keytab&lt;/code&gt; file using &lt;code&gt;$kadmin&lt;/code&gt;.&lt;/strong&gt;&lt;br&gt;
  Every time you generate a new entry for a principal to the KDC database, a key-version-number (kvno) is incremented. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Prepare a mount point for the NFSv4 share.&lt;/strong&gt;&lt;br&gt;
  Add an entry in the &lt;code&gt;/etc/fstab&lt;/code&gt; file (type nfs). It is not necessary to indicate any NFS version or other options, defaults will do.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Configure PAM to automatically generate a Kerberos TGT ticket at login.&lt;/strong&gt;&lt;br&gt;
  When you have a Kerberos KDC running with the relevant principals you can use &lt;code&gt;$kinit&lt;/code&gt; to generate a TGT ticket. When you try to access the NFS fileshare, a service ticket is automatically generated which grants you this access. In order to have the first step done in the background as well, you need to configure the &lt;a href="https://github.com/linux-pam/linux-pam"&gt;Pluggable Authentication Modules&lt;/a&gt; (PAM).
 &lt;a href="https://linuskarlsson.se/blog/acquiring-kerberos-ticket-upon-local-login/"&gt;This&lt;/a&gt; post describes a way how to do that in a pragmatic way. It relies on having both a local login &lt;em&gt;and&lt;/em&gt; Kerberos login with identical passwords, but for me this is fine.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h4&gt;NFS Server&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Enable the NFSv4 service in the NAS.&lt;/p&gt;
&lt;p&gt;&lt;img src="images/DSM_Files_Services_NFS.png" alt="Image: DSM Control Panel - File Sharing" width="800"/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Enter NFSv4 domain/realm under 'Advanced Settings'. No need to change anything regarding the size of the read/write packages. These are negotiated between server and client automatically.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src="images/DSM_Files_Services_NFS_Advanced_Settings.png" alt="Image: DSM Control Panel - File Sharing" width="400"/&gt; &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Import the &lt;code&gt;/etc/krbd5.keytab&lt;/code&gt;file from the linux client. In this setup, it should only contain the keys for the service principal we are interested in, the NAS.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src="images/DSM_Files_Services_NFS_Advanced_Settings_Kerberos_Keys.png" alt="Image: DSM Control Panel - File Sharing" width="400"/&gt; &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Map the principal ID from Kerberos database to a local user on the NAS.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src="images/DSM_Files_Services_NFS_Advanced_Settings_ID-Mapping.png" alt="Image: DSM Control Panel - File Sharing" width="400"/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="images/DSM_Files_Services_NFS_Advanced_Settings_ID-Mapping2.png" alt="Image: DSM Control Panel - File Sharing" width="400"/&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Now the server's Kerberos principal identifier will show on the first screen of the 'Advanced Settings'.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src="images/DSM_Files_Services_NFS_Advanced_Settings_Principal.png" alt="Image: DSM Control Panel - File Sharing" width="400"/&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Create NFS permission rule for the file share you want to connect to with the Linux client.&lt;/li&gt;
&lt;li&gt;Enter IP address of the Linux client.&lt;/li&gt;
&lt;li&gt;Read/write privilege&lt;/li&gt;
&lt;li&gt;Do not enable any static mapping here.&lt;/li&gt;
&lt;li&gt;Security: choose either &lt;em&gt;Kerberos integrity&lt;/em&gt; (krb5i - Kerberos Authentication and Integrity Checking) or Kerberos Privacy (krb5p - Kerberos Authentication, Integrity Checking and Traffic Encryption). The first Kerberos option only does authentication and provides no further security. &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src="images/DSM_Shared_Folder_NFS_Permissions.png" alt="Image: DSM Control Panel - File Sharing" width="400"/&gt;&lt;/p&gt;
&lt;p&gt;After all has been set up and services restarted, you can try to mount the NFSv4 file share on the NAS. You can check the status of the mount using&lt;br&gt;
&lt;code&gt;$findmnt -t nfs4 -l&lt;/code&gt;&lt;br&gt;
  It will show you the details on the file share.&lt;/p&gt;</content><category term="Blog"></category><category term="Kerberos"></category><category term="NFS4"></category><category term="Linux"></category><category term="Manjaro"></category><category term="Synology"></category><category term="NAS"></category></entry><entry><title>Building a modest Linux Deep Learning machine</title><link href="https://jwarmenhoven.github.io/Linux-Deep-Learning-Machine.html" rel="alternate"></link><published>2018-08-25T00:00:00+02:00</published><updated>2018-08-25T00:00:00+02:00</updated><author><name>Jordi Warmenhoven</name></author><id>tag:jwarmenhoven.github.io,2018-08-25:/Linux-Deep-Learning-Machine.html</id><summary type="html">&lt;p&gt;Some time ago I decided to move from a MacOS development environment back to Linux for exploring and working with Python datascience and statistical modelling libraries. Though most of the Python libraries and platforms offer support for MacOS, things are generally easier in  Linux. One avoids a lot of special â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Some time ago I decided to move from a MacOS development environment back to Linux for exploring and working with Python datascience and statistical modelling libraries. Though most of the Python libraries and platforms offer support for MacOS, things are generally easier in  Linux. One avoids a lot of special installation and compatability instructions. My first experience with Linux dates from 1996 when I bought a set of Slackware cdroms. Since then I have used Linux on various types of hardware, but not that much during the last few years. I mainly use &lt;a href="https://jupyter-notebook.readthedocs.io/en/latest/"&gt;Jupyter Notebooks&lt;/a&gt;, which are accessed through a webbrowser. So I will just run the Linux machine as a server and work in the notebooks through from my MacOS desktop using a browser. I find the Jupyter notebook a helpful tool, but &lt;a href="https://twitter.com/joelgrus/status/1033035196428378113"&gt;here&lt;/a&gt; are some valid points on its downsides.&lt;/p&gt;
&lt;p&gt;A second reason for wanting to switch back to Linux has to do with the fact that I want to take a look at running deep learning models on a Graphics Processing Unit (&lt;a href="https://blogs.nvidia.com/blog/2009/12/16/whats-the-difference-between-a-cpu-and-a-gpu/"&gt;GPU&lt;/a&gt;). My MacOS desktop (iMac) does not have compatible hardware or the possibility of installing such hardware. Today, the &lt;a href="https://developer.nvidia.com/computeworks"&gt;GPU's and toolkits from Nvidia&lt;/a&gt; are most common and deep learning frameworks like TensorFlow and Theano support mainly those. I must admit that the GPU was not a strict requirement for the new hardware: I am currently interested in probabilistic programming in PyMC3 and those type of models generally do not benefit from running on a GPU. Using the CPU for the computations is often faster! But since i wanted to take a look at Keras/Tensorflow I opted for a GPU anyway, making it the most expensive hardware component in my build...&lt;/p&gt;
&lt;p&gt;Below are some details on the hardware and the base installation of the Python libraries. It assumes basic knowledge of hardware components, Linux, Python and Deep Learning frameworks.&lt;/p&gt;
&lt;h3&gt;Hardware&lt;/h3&gt;
&lt;hr&gt;
&lt;p&gt;My objective was &lt;em&gt;not&lt;/em&gt; to build a high-end Deep Learning machine with multiple GPU's of the newest hardware available. I wanted to have a reasonably compact and average machine in terms of performance and cost. Checking component compatibility and reviews with help of &lt;a href="https://pcpartpicker.com/"&gt;pcpartpicker&lt;/a&gt; was very convenient. The actual installation of the hardware was not very difficult. Carefully read the manual of the motherboard and case. Those will pretty much show you in which order to put things together.&lt;/p&gt;
&lt;p&gt;&lt;img src="images/hardware_components.png" alt="Image: Hardware components" width="400"/&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Motherboard: &lt;a href="https://www.asus.com/uk/Motherboards/PRIME-B250M-PLUS/specifications/"&gt;ASUS Prime B250M-Plus&lt;/a&gt;&lt;/strong&gt; &lt;br&gt;
This motherboard has a B250 chipset with support for 6th/7th generation Skylake/Kaby Lake Intel Core processors. Initially I went for the B250M-K which has one slot for GPU instead of two and two slots for RAM instead of four. This would have been fine since I do not intend on running multiple GPU's or upgrade to more RAM. But as it turned out, the B250M-K is not compatible with the case I had bought: it has only one connector for a case fan whereas my case came with two fans. I really liked the case so I decided to change the motherboard since the extra cost was small.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;CPU: &lt;a href="https://ark.intel.com/products/97123"&gt;Intel Core i5 7500 3.4 GHz&lt;/a&gt;&lt;/strong&gt;   &lt;br&gt;
A 7th generation Kaby Lake processor with 4 cores from Q1 2017. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;CPU Cooler: &lt;a href="http://www.coolermaster.com/cooling/cpu-air-cooler/hyper-212-evo/"&gt;Cooler Master Hyper 212 EVO&lt;/a&gt;&lt;/strong&gt;&lt;br&gt;
The Intel CPU came with a fan but I bought this one afterwards. Mostly to reduce the noise somewhat. I do not think there would have been any problems with the Intel stock cooler since I am not going to overclock the CPU. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Video Card: &lt;a href="https://www.asus.com/uk/Graphics-Cards/PH-GTX1060-6G/specifications/"&gt;ASUS GeForce GTX 1060 6GB Phoenix&lt;/a&gt;&lt;/strong&gt;&lt;br&gt;
Not the newest and most capable GPU on the market, but enough for what I intend to use it for.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Memory: &lt;a href="https://www.corsair.com/eu/en/Categories/Products/Memory/VENGEANCE%C2%AE-LPX-16GB-%282-x-8GB%29-DDR4-DRAM-2400MHz-C16-Memory-Kit---Black/p/CMK16GX4M2Z2400C16"&gt;Corsair 16GB (2x 8GB) DDR4 2400MHz CL16 Vengeance&lt;/a&gt;&lt;/strong&gt;  &lt;br&gt;
The Motherboard supports a maximum of 64GB DDR4 @ 2400 MHz. It required a BIOS update for the motherboard to run the RAM at 2400MHz.   &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Storage: &lt;a href="https://www.samsung.com/uk/memory-storage/960-evo-nvme-m-2-ssd/MZ-V6E250BW/"&gt;Samsung 960 EVO 250GB&lt;/a&gt;&lt;/strong&gt;&lt;br&gt;
I wanted a SSD disk as the main storage disk.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Case: &lt;a href="http://www.fractal-design.com/home/product/cases/define-series/define-mini-c"&gt;Fractal Design Define Mini C Svart&lt;/a&gt;&lt;/strong&gt;&lt;br&gt;
Nice, compact mATX case. High quality finish and good manual.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Power Supply: &lt;a href="http://www.fractal-design.com/home/product/power-supplies/integra-m/integra-m-450w"&gt;Fractal Design Integra M 450W&lt;/a&gt;&lt;/strong&gt;&lt;br&gt;
All the components together do not draw that much power at all. This modest 450 Watt power supply works just fine. &lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The total price tag for the components was a little more than 1100 USD.&lt;/p&gt;
&lt;h3&gt;Software&lt;/h3&gt;
&lt;hr&gt;
&lt;p&gt;Instead of just copying the installation instructions of the various libraries here, I will just mentioned specific points which I think are especially important. You should read all notes in the context of &lt;em&gt;"At the time of installation"&lt;/em&gt;. Available versions and dependencies have likely changed since then.  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href="https://help.ubuntu.com/16.04/installation-guide/index.html"&gt;Ubuntu 16.04 LTS&lt;/a&gt;&lt;/strong&gt; &lt;br&gt;
I chose the 16.04 release over the more recent 18.04 because the latter is not explicitly mentioned as being compatible with the Nvidia Cuda Toolkit. Judging from various posts on the Internet there are ways to get it to work in 18.04, but I did not want to take any chances. I installed Ubuntu by means of a boot image on a &lt;a href="https://help.ubuntu.com/16.04/installation-guide/amd64/ch04s03.html"&gt;USB memory stick&lt;/a&gt;.  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href="https://developer.nvidia.com/cuda-toolkit-archive"&gt;Nvidia CUDA Toolkit 9.0&lt;/a&gt;&lt;/strong&gt;&lt;br&gt;
&lt;em&gt;"The NVIDIAÂ® CUDAÂ® Toolkit provides a development environment for creating high performance GPU-accelerated applications. With the CUDA Toolkit, you can develop, optimize and deploy your applications on GPU-accelerated embedded systems, desktop workstations, enterprise data centers, cloud-based platforms and HPC supercomputers."&lt;/em&gt;&lt;br&gt;
TensorFlow with GPU support in Ubuntu requires CUDA Toolkit 9.0. After carefully following the &lt;a href="https://docs.nvidia.com/cuda/archive/9.0/cuda-installation-guide-linux/index.html"&gt;installation and post-installation instructions&lt;/a&gt;, I did not encounter any problems with the Ubuntu deb packages. To make sure that my package manager does automatically upgrade to a never version of the toolkit I installed with &lt;code&gt;sudo apt-get install cuda-9.0&lt;/code&gt; instead of &lt;code&gt;sudo apt-get install cuda&lt;/code&gt;.  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href="https://developer.nvidia.com/cudnn"&gt;Nvidia cuDNN 7.1.4 for CUDA 9.0&lt;/a&gt;&lt;/strong&gt;&lt;br&gt;
&lt;em&gt;"The NVIDIA CUDAÂ® Deep Neural Network library (cuDNN) is a GPU-accelerated library of primitives for deep neural networks. cuDNN provides highly tuned implementations for standard routines such as forward and backward convolution, pooling, normalization, and activation layers. cuDNN is part of the NVIDIA Deep Learning SDK."&lt;/em&gt;&lt;br&gt;
I installed the deb packages as described in the &lt;a href="https://docs.nvidia.com/deeplearning/sdk/cudnn-archived/cudnn_714/cudnn-install/index.html#install-linux"&gt;documentation&lt;/a&gt;. You will have to register (free) as a developer to be able to download the library.  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href="https://www.anaconda.com/download/#linux"&gt;Anaconda 5.2 (Python 3.6)&lt;/a&gt;&lt;/strong&gt;&lt;br&gt;
I created a conda environment with Python version 3.6 and installed the typical PyData libraries like Pandas, Numpy, Scipy, Matplotlib and Jupyter.    &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href="http://deeplearning.net/software/theano/install_ubuntu.html"&gt;Theano 1.0.2&lt;/a&gt;&lt;/strong&gt;&lt;br&gt;
Bleeding-Edge installation as described in the documentation: &lt;code&gt;pip install&lt;/code&gt; from GitHub. I did this within the conda environment. The Ubuntu installation instructions appear a bit dated with regards to the required versions of the dependent libraries. Just install the libraries mentioned using &lt;code&gt;conda install [library]&lt;/code&gt;. I installed libgpuarray following the step-by-step system install description (note &lt;code&gt;cmake&lt;/code&gt; requirement).&lt;br&gt;
Read the documentation about the configuration of Theano using the &lt;code&gt;.theanorc&lt;/code&gt; file.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href="http://docs.pymc.io/"&gt;PyMC3 3.5&lt;/a&gt;&lt;/strong&gt;&lt;br&gt;
PyMC3 is a Python package for Bayesian modelling and relies on Theano for computations. I installed the development branch with &lt;code&gt;pip install&lt;/code&gt; from GitHub within the conda environment. When testing some code to see if I could use the GPU with Theano, I found out that PyMC3 tries to do parallel MCMC sampling by default. It assumes that you have multiple GPU's and this will result in a RuntimeError. Specify &lt;code&gt;cores=1&lt;/code&gt; when calling the &lt;code&gt;pm.sample()&lt;/code&gt; method. If you have configured Theano to use the CPU instead of the GPU  (&lt;code&gt;device = cpu&lt;/code&gt; in your &lt;code&gt;.theanorc&lt;/code&gt; file), you can enter the number of cores of your cpu. As mentioned earlier, the GPU does generally not speed up computations with PyMC3 models.  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href="https://www.tensorflow.org/install/install_linux"&gt;TensorFlow 1.9&lt;/a&gt;&lt;/strong&gt;&lt;br&gt;
Installed in the conda environment using pip and the URL of the TensorFlow package with GPU support for Python 3.6.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href="https://keras.io/"&gt;Keras 2.2.2&lt;/a&gt;&lt;/strong&gt;&lt;br&gt;
Installed in the conda environment using pip. It will use TensorFlow as its backend.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are of course more base packages and libraries that one would install in a typical development environment, but the above are the main parts with regards to Deep Learning and Bayesian modelling. Furthermore, the modelling and Deep Learning ecosystem for Python is &lt;a href="https://t.co/Zn6pjXplXB"&gt;developping fast&lt;/a&gt;. Many more frameworks are available. I am looking forward to exploring these!&lt;/p&gt;</content><category term="Blog"></category><category term="Linux"></category><category term="Deep Learning"></category><category term="GPU"></category><category term="Python"></category></entry></feed>